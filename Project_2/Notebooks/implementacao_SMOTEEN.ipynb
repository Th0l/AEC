{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_0null = pd.read_csv(\"training_0null.csv\")\n",
    "teste_0null = pd.read_csv(\"test_0null.csv\")\n",
    "#-------------------------------------------\n",
    "treino_0null_X = treino_0null.drop(columns=['salary','fnlwgt']) \n",
    "treino_0null_Y = treino_0null['salary']\n",
    "teste_0null_X = teste_0null.drop(columns=['salary','fnlwgt'])  \n",
    "teste_0null_Y = teste_0null['salary']\n",
    "\n",
    "\n",
    "treino_mode = pd.read_csv(\"training_mode.csv\")\n",
    "teste_mode = pd.read_csv(\"test_mode.csv\")\n",
    "#-------------------------------------------\n",
    "treino_mode_X = treino_mode.drop(columns=['salary','fnlwgt']) \n",
    "treino_mode_Y = treino_mode['salary']\n",
    "teste_mode_X = teste_mode.drop(columns=['salary','fnlwgt'])  \n",
    "teste_mode_Y = teste_mode['salary']\n",
    "\n",
    "treino_knn = pd.read_csv(\"training_knn.csv\")\n",
    "teste_knn = pd.read_csv(\"test_knn.csv\")\n",
    "#-------------------------------------------\n",
    "treino_knn_X = treino_knn.drop(columns=['salary','fnlwgt']) \n",
    "treino_knn_Y = treino_knn['salary']\n",
    "teste_knn_X = teste_knn.drop(columns=['salary','fnlwgt'])  \n",
    "teste_knn_Y = teste_knn['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_strings = pd.read_csv(\"training_0null_strings.csv\")\n",
    "teste_strings = pd.read_csv(\"test_0null_strings.csv\")\n",
    "\n",
    "treino_strings_X = treino_strings.drop(columns=['salary','fnlwgt']) \n",
    "treino_strings_Y = treino_strings['salary']\n",
    "teste_strings_X = teste_strings.drop(columns=['salary','fnlwgt'])  \n",
    "teste_strings_Y = teste_strings['salary']\n",
    "\n",
    "categorical = ['workclass', 'maritalstatus', 'occupation', 'relationship', 'race', 'sex', 'nativecountry']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        treino_strings_X[feature] = le.fit_transform(treino_strings_X[feature])\n",
    "        teste_strings_X[feature] = le.transform(teste_strings_X[feature])\n",
    "        \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "treino_strings_X = pd.DataFrame(scaler.fit_transform(treino_strings_X), columns = treino_strings_X.columns)\n",
    "\n",
    "teste_strings_X = pd.DataFrame(scaler.transform(teste_strings_X), columns = teste_strings_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Apply SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onull = SMOTEENN(random_state=0)\n",
    "mode = SMOTEENN(random_state=0)\n",
    "knn = SMOTEENN(random_state=0)\n",
    "strings = SMOTEENN(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_0null_X, treino_0null_Y = onull.fit_sample(treino_0null_X,treino_0null_Y)\n",
    "treino_0null_X, treino_0null_Y = shuffle(treino_0null_X,treino_0null_Y)\n",
    "\n",
    "treino_mode_X, treino_mode_Y = mode.fit_sample(treino_mode_X,treino_mode_Y)\n",
    "treino_mode_X, treino_mode_Y = shuffle(treino_mode_X,treino_mode_Y)\n",
    "\n",
    "treino_knn_X, treino_knn_Y = knn.fit_sample(treino_knn_X,treino_knn_Y)\n",
    "treino_knn_X, treino_knn_Y = shuffle(treino_knn_X,treino_knn_Y)\n",
    "\n",
    "treino_strings_X, treino_strings_Y = strings.fit_sample(treino_strings_X,treino_strings_Y)\n",
    "treino_strings_X, treino_strings_Y = shuffle(treino_strings_X,treino_strings_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Função a correr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(xTrain,yTrain,xTest,yTest):\n",
    "    counter = 0\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(class_weight='balanced',max_iter=500),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(class_weight='balanced'),\n",
    "        GaussianNB(),\n",
    "        RandomForestClassifier(max_depth=20,class_weight='balanced'),\n",
    "        KMeans(n_clusters=2)\n",
    "    ]\n",
    "    \n",
    "    names = [\n",
    "        \"LogisticRegression\", \"KNeighbours\",\n",
    "        \"SVM\", \"Gaussian NaiveBayes\",\n",
    "        \"RandomForest\", \"KMeans\" ]\n",
    "    \n",
    "    for name, alg in zip(names,classifiers):\n",
    "        if(counter == 5):\n",
    "            xTrain = pd.concat([xTrain, xTest], ignore_index=True)\n",
    "            yTrain = pd.concat([yTrain, yTest], ignore_index=True)\n",
    "            \n",
    "        alg.fit(xTrain,yTrain)\n",
    "        predicted = alg.predict(xTest)\n",
    "        \n",
    "        print(name)\n",
    "        #---------------------------------------------------\n",
    "        print(classification_report(yTest,predicted))\n",
    "        print(pd.crosstab(yTest,predicted, rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "        #---------------------------------------------------\n",
    "        score = accuracy_score(yTest,predicted)\n",
    "        print('Accuracy:{0:f}'.format(score))\n",
    "        print(\"#---------------------------------------------------\")\n",
    "        \n",
    "        counter+=1\n",
    "    \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodod\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.80     11360\n",
      "           1       0.47      0.74      0.57      3700\n",
      "\n",
      "    accuracy                           0.73     15060\n",
      "   macro avg       0.68      0.73      0.69     15060\n",
      "weighted avg       0.79      0.73      0.75     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          8244  3116  11360\n",
      "1           951  2749   3700\n",
      "All        9195  5865  15060\n",
      "Accuracy:0.729947\n",
      "#---------------------------------------------------\n",
      "KNeighbours\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84     11360\n",
      "           1       0.53      0.84      0.65      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.73      0.80      0.74     15060\n",
      "weighted avg       0.83      0.78      0.79     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          8624  2736  11360\n",
      "1           610  3090   3700\n",
      "All        9234  5826  15060\n",
      "Accuracy:0.777822\n",
      "#---------------------------------------------------\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87     11360\n",
      "           1       0.67      0.29      0.41      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.74      0.62      0.64     15060\n",
      "weighted avg       0.77      0.79      0.76     15060\n",
      "\n",
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10832   528  11360\n",
      "1           2609  1091   3700\n",
      "All        13441  1619  15060\n",
      "Accuracy:0.791700\n",
      "#---------------------------------------------------\n",
      "Gaussian NaiveBayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     11360\n",
      "           1       0.66      0.51      0.58      3700\n",
      "\n",
      "    accuracy                           0.82     15060\n",
      "   macro avg       0.76      0.71      0.73     15060\n",
      "weighted avg       0.81      0.82      0.81     15060\n",
      "\n",
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10384   976  11360\n",
      "1           1796  1904   3700\n",
      "All        12180  2880  15060\n",
      "Accuracy:0.815936\n",
      "#---------------------------------------------------\n",
      "RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     11360\n",
      "           1       0.60      0.82      0.69      3700\n",
      "\n",
      "    accuracy                           0.82     15060\n",
      "   macro avg       0.77      0.82      0.78     15060\n",
      "weighted avg       0.85      0.82      0.83     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          9341  2019  11360\n",
      "1           656  3044   3700\n",
      "All        9997  5063  15060\n",
      "Accuracy:0.822377\n",
      "#---------------------------------------------------\n",
      "KMeans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     11360\n",
      "           1       0.24      0.98      0.39      3700\n",
      "\n",
      "    accuracy                           0.24     15060\n",
      "   macro avg       0.12      0.49      0.19     15060\n",
      "weighted avg       0.06      0.24      0.10     15060\n",
      "\n",
      "Predicted   0      1    All\n",
      "Actual                     \n",
      "0           0  11360  11360\n",
      "1          81   3619   3700\n",
      "All        81  14979  15060\n",
      "Accuracy:0.240305\n",
      "#---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluator(treino_0null_X,treino_0null_Y,teste_0null_X,teste_0null_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodod\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80     11360\n",
      "           1       0.47      0.75      0.58      3700\n",
      "\n",
      "    accuracy                           0.73     15060\n",
      "   macro avg       0.68      0.74      0.69     15060\n",
      "weighted avg       0.79      0.73      0.74     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          8181  3179  11360\n",
      "1           918  2782   3700\n",
      "All        9099  5961  15060\n",
      "Accuracy:0.727955\n",
      "#---------------------------------------------------\n",
      "KNeighbours\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84     11360\n",
      "           1       0.53      0.83      0.65      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.73      0.80      0.74     15060\n",
      "weighted avg       0.83      0.78      0.79     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          8680  2680  11360\n",
      "1           636  3064   3700\n",
      "All        9316  5744  15060\n",
      "Accuracy:0.779814\n",
      "#---------------------------------------------------\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87     11360\n",
      "           1       0.67      0.29      0.41      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.74      0.62      0.64     15060\n",
      "weighted avg       0.77      0.79      0.76     15060\n",
      "\n",
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10830   530  11360\n",
      "1           2609  1091   3700\n",
      "All        13439  1621  15060\n",
      "Accuracy:0.791567\n",
      "#---------------------------------------------------\n",
      "Gaussian NaiveBayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88     11360\n",
      "           1       0.66      0.53      0.59      3700\n",
      "\n",
      "    accuracy                           0.82     15060\n",
      "   macro avg       0.76      0.72      0.74     15060\n",
      "weighted avg       0.81      0.82      0.81     15060\n",
      "\n",
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10354  1006  11360\n",
      "1           1733  1967   3700\n",
      "All        12087  2973  15060\n",
      "Accuracy:0.818127\n",
      "#---------------------------------------------------\n",
      "RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88     11360\n",
      "           1       0.60      0.83      0.70      3700\n",
      "\n",
      "    accuracy                           0.82     15060\n",
      "   macro avg       0.77      0.83      0.79     15060\n",
      "weighted avg       0.85      0.82      0.83     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          9352  2008  11360\n",
      "1           638  3062   3700\n",
      "All        9990  5070  15060\n",
      "Accuracy:0.824303\n",
      "#---------------------------------------------------\n",
      "KMeans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86     11360\n",
      "           1       1.00      0.02      0.04      3700\n",
      "\n",
      "    accuracy                           0.76     15060\n",
      "   macro avg       0.88      0.51      0.45     15060\n",
      "weighted avg       0.82      0.76      0.66     15060\n",
      "\n",
      "Predicted      0   1    All\n",
      "Actual                     \n",
      "0          11360   0  11360\n",
      "1           3619  81   3700\n",
      "All        14979  81  15060\n",
      "Accuracy:0.759695\n",
      "#---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluator(treino_mode_X,treino_mode_Y,teste_mode_X,teste_mode_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodod\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.70      0.79     11360\n",
      "         1.0       0.46      0.78      0.58      3700\n",
      "\n",
      "    accuracy                           0.72     15060\n",
      "   macro avg       0.68      0.74      0.68     15060\n",
      "weighted avg       0.80      0.72      0.74     15060\n",
      "\n",
      "Predicted   0.0   1.0    All\n",
      "Actual                      \n",
      "0.0        7965  3395  11360\n",
      "1.0         819  2881   3700\n",
      "All        8784  6276  15060\n",
      "Accuracy:0.720186\n",
      "#---------------------------------------------------\n",
      "KNeighbours\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.74      0.83     11360\n",
      "         1.0       0.51      0.85      0.64      3700\n",
      "\n",
      "    accuracy                           0.77     15060\n",
      "   macro avg       0.73      0.79      0.73     15060\n",
      "weighted avg       0.83      0.77      0.78     15060\n",
      "\n",
      "Predicted   0.0   1.0    All\n",
      "Actual                      \n",
      "0.0        8372  2988  11360\n",
      "1.0         548  3152   3700\n",
      "All        8920  6140  15060\n",
      "Accuracy:0.765206\n",
      "#---------------------------------------------------\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.95      0.87     11360\n",
      "         1.0       0.68      0.29      0.41      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.74      0.62      0.64     15060\n",
      "weighted avg       0.77      0.79      0.76     15060\n",
      "\n",
      "Predicted    0.0   1.0    All\n",
      "Actual                       \n",
      "0.0        10839   521  11360\n",
      "1.0         2609  1091   3700\n",
      "All        13448  1612  15060\n",
      "Accuracy:0.792165\n",
      "#---------------------------------------------------\n",
      "Gaussian NaiveBayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88     11360\n",
      "         1.0       0.64      0.57      0.61      3700\n",
      "\n",
      "    accuracy                           0.82     15060\n",
      "   macro avg       0.75      0.73      0.74     15060\n",
      "weighted avg       0.81      0.82      0.81     15060\n",
      "\n",
      "Predicted    0.0   1.0    All\n",
      "Actual                       \n",
      "0.0        10162  1198  11360\n",
      "1.0         1575  2125   3700\n",
      "All        11737  3323  15060\n",
      "Accuracy:0.815870\n",
      "#---------------------------------------------------\n",
      "RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88     11360\n",
      "         1.0       0.61      0.81      0.70      3700\n",
      "\n",
      "    accuracy                           0.83     15060\n",
      "   macro avg       0.77      0.82      0.79     15060\n",
      "weighted avg       0.85      0.83      0.83     15060\n",
      "\n",
      "Predicted    0.0   1.0    All\n",
      "Actual                       \n",
      "0.0         9456  1904  11360\n",
      "1.0          701  2999   3700\n",
      "All        10157  4903  15060\n",
      "Accuracy:0.827025\n",
      "#---------------------------------------------------\n",
      "KMeans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      1.00      0.86     11360\n",
      "         1.0       1.00      0.02      0.04      3700\n",
      "\n",
      "    accuracy                           0.76     15060\n",
      "   macro avg       0.88      0.51      0.45     15060\n",
      "weighted avg       0.82      0.76      0.66     15060\n",
      "\n",
      "Predicted      0   1    All\n",
      "Actual                     \n",
      "0.0        11360   0  11360\n",
      "1.0         3619  81   3700\n",
      "All        14979  81  15060\n",
      "Accuracy:0.759695\n",
      "#---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluator(treino_knn_X,treino_knn_Y,teste_knn_X,teste_knn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81     11360\n",
      "           1       0.49      0.78      0.60      3700\n",
      "\n",
      "    accuracy                           0.74     15060\n",
      "   macro avg       0.70      0.76      0.71     15060\n",
      "weighted avg       0.81      0.74      0.76     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          8336  3024  11360\n",
      "1           817  2883   3700\n",
      "All        9153  5907  15060\n",
      "Accuracy:0.744954\n",
      "#---------------------------------------------------\n",
      "KNeighbours\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84     11360\n",
      "           1       0.53      0.82      0.65      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.73      0.79      0.74     15060\n",
      "weighted avg       0.83      0.78      0.79     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          8693  2667  11360\n",
      "1           654  3046   3700\n",
      "All        9347  5713  15060\n",
      "Accuracy:0.779482\n",
      "#---------------------------------------------------\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84     11360\n",
      "           1       0.54      0.86      0.67      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.74      0.81      0.76     15060\n",
      "weighted avg       0.85      0.79      0.80     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          8670  2690  11360\n",
      "1           504  3196   3700\n",
      "All        9174  5886  15060\n",
      "Accuracy:0.787915\n",
      "#---------------------------------------------------\n",
      "Gaussian NaiveBayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     11360\n",
      "           1       0.64      0.49      0.56      3700\n",
      "\n",
      "    accuracy                           0.81     15060\n",
      "   macro avg       0.74      0.70      0.72     15060\n",
      "weighted avg       0.79      0.81      0.80     15060\n",
      "\n",
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10317  1043  11360\n",
      "1           1871  1829   3700\n",
      "All        12188  2872  15060\n",
      "Accuracy:0.806507\n",
      "#---------------------------------------------------\n",
      "RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87     11360\n",
      "           1       0.59      0.82      0.69      3700\n",
      "\n",
      "    accuracy                           0.81     15060\n",
      "   macro avg       0.76      0.82      0.78     15060\n",
      "weighted avg       0.85      0.81      0.82     15060\n",
      "\n",
      "Predicted     0     1    All\n",
      "Actual                      \n",
      "0          9240  2120  11360\n",
      "1           667  3033   3700\n",
      "All        9907  5153  15060\n",
      "Accuracy:0.814940\n",
      "#---------------------------------------------------\n",
      "KMeans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86     11360\n",
      "           1       1.00      0.02      0.04      3700\n",
      "\n",
      "    accuracy                           0.76     15060\n",
      "   macro avg       0.88      0.51      0.45     15060\n",
      "weighted avg       0.82      0.76      0.66     15060\n",
      "\n",
      "Predicted      0   1    All\n",
      "Actual                     \n",
      "0          11360   0  11360\n",
      "1           3619  81   3700\n",
      "All        14979  81  15060\n",
      "Accuracy:0.759695\n",
      "#---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluator(treino_strings_X,treino_strings_Y,teste_strings_X,teste_strings_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
