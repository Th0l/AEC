{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Without nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_0null = pd.read_csv(\"training_0null.csv\")\n",
    "teste_0null = pd.read_csv(\"test_0null.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_0null_X = treino_0null.drop(columns=['salary']) \n",
    "treino_0null_Y = treino_0null['salary']\n",
    "teste_0null_X = teste_0null.drop(columns=['salary'])  \n",
    "teste_0null_Y = teste_0null['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model to predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel1 = LogisticRegression(max_iter=500)\n",
    "logmodel1.fit(treino_0null_X,treino_0null_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictNotNull = logmodel1.predict(teste_0null_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy of predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87     11360\n",
      "           1       0.63      0.30      0.41      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.72      0.62      0.64     15060\n",
      "weighted avg       0.76      0.79      0.76     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_0null_Y,predictNotNull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10717   643  11360\n",
      "1           2591  1109   3700\n",
      "All        13308  1752  15060\n"
     ]
    }
   ],
   "source": [
    "confusionNotNull = pd.crosstab(teste_0null_Y, predictNotNull, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionNotNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.785259\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_0null_Y,predictNotNull)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_0null_X,treino_0null_Y = oversample.fit_resample(treino_0null_X,treino_0null_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_0null_X,treino_0null_Y = undersample.fit_resample(treino_0null_X,treino_0null_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel1 = LogisticRegression(max_iter=500)\n",
    "logmodel1.fit(treino_0null_X,treino_0null_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictNotNull = logmodel1.predict(teste_0null_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.87     11360\n",
      "           1       0.60      0.30      0.40      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.70      0.62      0.63     15060\n",
      "weighted avg       0.76      0.78      0.75     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_0null_Y,predictNotNull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10619   741  11360\n",
      "1           2573  1127   3700\n",
      "All        13192  1868  15060\n"
     ]
    }
   ],
   "source": [
    "confusionNotNull = pd.crosstab(teste_0null_Y,predictNotNull, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionNotNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.779947\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_0null_Y,predictNotNull)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Mode as null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_mode = pd.read_csv(\"training_mode.csv\")\n",
    "teste_mode = pd.read_csv(\"test_mode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_mode_X = treino_mode.drop(columns=['salary']) \n",
    "treino_mode_Y = treino_mode['salary']\n",
    "teste_mode_X = teste_mode.drop(columns=['salary'])  \n",
    "teste_mode_Y = teste_mode['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model to predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel2 = LogisticRegression(max_iter=500)\n",
    "logmodel2.fit(treino_mode_X,treino_mode_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictYMode = logmodel2.predict(teste_mode_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy of predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     11360\n",
      "           1       0.73      0.26      0.39      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.76      0.62      0.63     15060\n",
      "weighted avg       0.78      0.79      0.76     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_mode_Y,predictYMode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10992   368  11360\n",
      "1           2722   978   3700\n",
      "All        13714  1346  15060\n"
     ]
    }
   ],
   "source": [
    "confusionMode = pd.crosstab(teste_mode_Y, predictYMode, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.794821\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_mode_Y,predictYMode)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_mode_X,treino_mode_Y = oversample.fit_resample(treino_mode_X,treino_mode_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_mode_X,treino_mode_Y = undersample.fit_resample(treino_mode_X,treino_mode_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel2 = LogisticRegression(max_iter=500)\n",
    "logmodel2.fit(treino_mode_X,treino_mode_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictYMode = logmodel2.predict(teste_mode_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83     11360\n",
      "           1       0.48      0.42      0.44      3700\n",
      "\n",
      "    accuracy                           0.74     15060\n",
      "   macro avg       0.65      0.63      0.64     15060\n",
      "weighted avg       0.73      0.74      0.74     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_mode_Y,predictYMode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0           9663  1697  11360\n",
      "1           2158  1542   3700\n",
      "All        11821  3239  15060\n"
     ]
    }
   ],
   "source": [
    "confusionMode = pd.crosstab(teste_mode_Y, predictYMode, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.744024\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_mode_Y,predictYMode)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - KNN as null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_knn = pd.read_csv(\"training_knn.csv\")\n",
    "teste_knn = pd.read_csv(\"test_knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_knn_X = treino_knn.drop(columns=['salary']) \n",
    "treino_knn_Y = treino_knn['salary']\n",
    "teste_knn_X = teste_knn.drop(columns=['salary'])  \n",
    "teste_knn_Y = teste_knn['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model to predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel3 = LogisticRegression(max_iter=500)\n",
    "logmodel3.fit(treino_knn_X,treino_knn_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictYKNN = logmodel3.predict(teste_knn_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy of predition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.95      0.87     11360\n",
      "         1.0       0.64      0.28      0.39      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.72      0.62      0.63     15060\n",
      "weighted avg       0.76      0.78      0.75     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_knn_Y,predictYKNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0.0   1.0    All\n",
      "Actual                       \n",
      "0.0        10766   594  11360\n",
      "1.0         2654  1046   3700\n",
      "All        13420  1640  15060\n"
     ]
    }
   ],
   "source": [
    "confusionKNN = pd.crosstab(teste_knn_Y, predictYKNN, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.784329\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_knn_Y,predictYKNN)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_knn_X,treino_knn_Y = oversample.fit_resample(treino_knn_X,treino_knn_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_knn_X,treino_knn_Y = undersample.fit_resample(treino_knn_X,treino_knn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel3 = LogisticRegression(max_iter=500)\n",
    "logmodel3.fit(treino_knn_X,treino_knn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictYKNN = logmodel3.predict(teste_knn_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.85      0.83     11360\n",
      "         1.0       0.48      0.42      0.45      3700\n",
      "\n",
      "    accuracy                           0.74     15060\n",
      "   macro avg       0.65      0.63      0.64     15060\n",
      "weighted avg       0.73      0.74      0.74     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_knn_Y,predictYKNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0.0   1.0    All\n",
      "Actual                       \n",
      "0.0         9651  1709  11360\n",
      "1.0         2146  1554   3700\n",
      "All        11797  3263  15060\n"
     ]
    }
   ],
   "source": [
    "confusionKNN = pd.crosstab(teste_knn_Y, predictYKNN, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.744024\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_knn_Y,predictYKNN)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - No null but using scale instead of ints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_strings = pd.read_csv(\"training_0null_strings.csv\")\n",
    "teste_strings = pd.read_csv(\"test_0null_strings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_strings_X = treino_strings.drop(columns=['salary']) \n",
    "treino_strings_Y = treino_strings['salary']\n",
    "teste_strings_X = teste_strings.drop(columns=['salary'])  \n",
    "teste_strings_Y = teste_strings['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = ['workclass', 'maritalstatus', 'occupation', 'relationship', 'race', 'sex', 'nativecountry']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        treino_strings_X[feature] = le.fit_transform(treino_strings_X[feature])\n",
    "        teste_strings_X[feature] = le.transform(teste_strings_X[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "treino_strings_X = pd.DataFrame(scaler.fit_transform(treino_strings_X), columns = treino_strings_X.columns)\n",
    "\n",
    "teste_strings_X = pd.DataFrame(scaler.transform(teste_strings_X), columns = teste_strings_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model to predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel4 = LogisticRegression(max_iter=500)\n",
    "logmodel4.fit(treino_strings_X,treino_strings_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictScale = logmodel4.predict(teste_strings_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy of predition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     11360\n",
      "           1       0.70      0.46      0.56      3700\n",
      "\n",
      "    accuracy                           0.82     15060\n",
      "   macro avg       0.77      0.70      0.72     15060\n",
      "weighted avg       0.81      0.82      0.81     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_strings_Y,predictScale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10643   717  11360\n",
      "1           1996  1704   3700\n",
      "All        12639  2421  15060\n"
     ]
    }
   ],
   "source": [
    "confusionScale = pd.crosstab(teste_strings_Y, predictScale, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.819854\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_strings_Y,predictScale)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_strings_X,treino_strings_Y = oversample.fit_resample(treino_strings_X,treino_strings_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_strings_X,treino_strings_Y = undersample.fit_resample(treino_strings_X,treino_strings_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel4 = LogisticRegression(max_iter=500)\n",
    "logmodel4.fit(treino_strings_X,treino_strings_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictScale = logmodel4.predict(teste_strings_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     11360\n",
      "           1       0.57      0.65      0.61      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.73      0.75      0.73     15060\n",
      "weighted avg       0.80      0.79      0.80     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_strings_Y,predictScale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0           9562  1798  11360\n",
      "1           1296  2404   3700\n",
      "All        10858  4202  15060\n"
     ]
    }
   ],
   "source": [
    "confusionScale = pd.crosstab(teste_strings_Y, predictScale, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.794555\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_strings_Y,predictScale)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
