{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Without nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_0null = pd.read_csv(\"training_0null.csv\")\n",
    "teste_0null = pd.read_csv(\"test_0null.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_0null_X = treino_0null.drop(columns=['salary']) \n",
    "treino_0null_Y = treino_0null['salary']\n",
    "teste_0null_X = teste_0null.drop(columns=['salary'])  \n",
    "teste_0null_Y = teste_0null['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model to predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(treino_0null_X,treino_0null_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svc_model.predict(teste_0null_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     11360\n",
      "           1       0.97      0.15      0.27      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.88      0.58      0.57     15060\n",
      "weighted avg       0.83      0.79      0.73     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_0null_Y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0    1    All\n",
      "Actual                      \n",
      "0          11341   19  11360\n",
      "1           3131  569   3700\n",
      "All        14472  588  15060\n"
     ]
    }
   ],
   "source": [
    "confusionNotNull = pd.crosstab(teste_0null_Y,predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionNotNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.790837\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_0null_Y,predictions)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_0null_X,treino_0null_Y = oversample.fit_resample(treino_0null_X,treino_0null_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_0null_X,treino_0null_Y = undersample.fit_resample(treino_0null_X,treino_0null_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(treino_0null_X,treino_0null_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     11360\n",
      "           1       0.97      0.15      0.27      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.88      0.58      0.57     15060\n",
      "weighted avg       0.83      0.79      0.73     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_0null_Y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0    1    All\n",
      "Actual                      \n",
      "0          11341   19  11360\n",
      "1           3131  569   3700\n",
      "All        14472  588  15060\n"
     ]
    }
   ],
   "source": [
    "confusionNotNull = pd.crosstab(teste_0null_Y,predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionNotNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.790837\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_0null_Y,predictions)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Mode as null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_mode = pd.read_csv(\"training_mode.csv\")\n",
    "teste_mode = pd.read_csv(\"test_mode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_mode_X = treino_mode.drop(columns=['salary']) \n",
    "treino_mode_Y = treino_mode['salary']\n",
    "teste_mode_X = teste_mode.drop(columns=['salary'])  \n",
    "teste_mode_Y = teste_mode['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_mode = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_mode.fit(treino_mode_X,treino_mode_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mode = svc_model_mode.predict(teste_mode_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     11360\n",
      "           1       0.96      0.16      0.27      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.87      0.58      0.57     15060\n",
      "weighted avg       0.83      0.79      0.73     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_mode_Y,predictions_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0    1    All\n",
      "Actual                      \n",
      "0          11339   21  11360\n",
      "1           3124  576   3700\n",
      "All        14463  597  15060\n"
     ]
    }
   ],
   "source": [
    "confusionMode = pd.crosstab(teste_mode_Y,predictions_mode, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.791169\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_mode_Y,predictions_mode)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_mode_X,treino_mode_Y = oversample.fit_resample(treino_mode_X,treino_mode_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_mode_X,treino_mode_Y = undersample.fit_resample(treino_mode_X,treino_mode_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_mode = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_mode.fit(treino_mode_X,treino_mode_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mode = svc_model_mode.predict(teste_mode_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88     11360\n",
      "           1       0.89      0.18      0.30      3700\n",
      "\n",
      "    accuracy                           0.79     15060\n",
      "   macro avg       0.84      0.59      0.59     15060\n",
      "weighted avg       0.81      0.79      0.74     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_mode_Y,predictions_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0    1    All\n",
      "Actual                      \n",
      "0          11282   78  11360\n",
      "1           3044  656   3700\n",
      "All        14326  734  15060\n"
     ]
    }
   ],
   "source": [
    "confusionMode = pd.crosstab(teste_mode_Y,predictions_mode, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.792696\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_mode_Y,predictions_mode)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - KNN as null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_knn = pd.read_csv(\"training_knn.csv\")\n",
    "teste_knn = pd.read_csv(\"test_knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_knn_X = treino_knn.drop(columns=['salary']) \n",
    "treino_knn_Y = treino_knn['salary']\n",
    "teste_knn_X = teste_knn.drop(columns=['salary'])  \n",
    "teste_knn_Y = teste_knn['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_knn = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_knn.fit(teste_knn_X,teste_knn_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = svc_model_knn.predict(teste_knn_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      1.00      0.87     11360\n",
      "         1.0       0.99      0.11      0.20      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.88      0.56      0.54     15060\n",
      "weighted avg       0.83      0.78      0.71     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_knn_Y,predictions_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0.0  1.0    All\n",
      "Actual                      \n",
      "0.0        11354    6  11360\n",
      "1.0         3290  410   3700\n",
      "All        14644  416  15060\n"
     ]
    }
   ],
   "source": [
    "confusionKNN = pd.crosstab(teste_knn_Y,predictions_knn, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.781142\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_knn_Y,predictions_knn)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_knn_X,treino_knn_Y = oversample.fit_resample(treino_knn_X,treino_knn_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_knn_X,treino_knn_Y = undersample.fit_resample(treino_knn_X,treino_knn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_knn = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_knn.fit(teste_knn_X,teste_knn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = svc_model_knn.predict(teste_knn_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      1.00      0.87     11360\n",
      "         1.0       0.99      0.11      0.20      3700\n",
      "\n",
      "    accuracy                           0.78     15060\n",
      "   macro avg       0.88      0.56      0.54     15060\n",
      "weighted avg       0.83      0.78      0.71     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_knn_Y,predictions_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0.0  1.0    All\n",
      "Actual                      \n",
      "0.0        11354    6  11360\n",
      "1.0         3290  410   3700\n",
      "All        14644  416  15060\n"
     ]
    }
   ],
   "source": [
    "confusionKNN = pd.crosstab(teste_knn_Y,predictions_knn, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.781142\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_knn_Y,predictions_knn)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - No null but using scale instead of ints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_strings = pd.read_csv(\"training_0null_strings.csv\")\n",
    "teste_strings = pd.read_csv(\"test_0null_strings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_strings_X = treino_strings.drop(columns=['salary']) \n",
    "treino_strings_Y = treino_strings['salary']\n",
    "teste_strings_X = teste_strings.drop(columns=['salary'])  \n",
    "teste_strings_Y = teste_strings['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = ['workclass', 'maritalstatus', 'occupation', 'relationship', 'race', 'sex', 'nativecountry']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        treino_strings_X[feature] = le.fit_transform(treino_strings_X[feature])\n",
    "        teste_strings_X[feature] = le.transform(teste_strings_X[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "treino_strings_X = pd.DataFrame(scaler.fit_transform(treino_strings_X), columns = treino_strings_X.columns)\n",
    "\n",
    "teste_strings_X = pd.DataFrame(scaler.transform(teste_strings_X), columns = teste_strings_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_str = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_str.fit(treino_strings_X,treino_strings_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_scale = svc_model_str.predict(teste_strings_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     11360\n",
      "           1       0.76      0.54      0.63      3700\n",
      "\n",
      "    accuracy                           0.85     15060\n",
      "   macro avg       0.81      0.74      0.77     15060\n",
      "weighted avg       0.84      0.85      0.84     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_strings_Y,predictions_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10719   641  11360\n",
      "1           1686  2014   3700\n",
      "All        12405  2655  15060\n"
     ]
    }
   ],
   "source": [
    "confusionScale = pd.crosstab(teste_strings_Y,predictions_scale, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.845485\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_strings_Y,predictions_scale)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "treino_strings_X,treino_strings_Y = oversample.fit_resample(treino_strings_X,treino_strings_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "treino_strings_X,treino_strings_Y = undersample.fit_resample(treino_strings_X,treino_strings_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_str = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_str.fit(treino_strings_X,treino_strings_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_scale = svc_model_str.predict(teste_strings_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     11360\n",
      "           1       0.60      0.80      0.68      3700\n",
      "\n",
      "    accuracy                           0.82     15060\n",
      "   macro avg       0.76      0.81      0.78     15060\n",
      "weighted avg       0.84      0.82      0.83     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(teste_strings_Y,predictions_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0           9362  1998  11360\n",
      "1            749  2951   3700\n",
      "All        10111  4949  15060\n"
     ]
    }
   ],
   "source": [
    "confusionScale = pd.crosstab(teste_strings_Y,predictions_scale, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.817596\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(teste_strings_Y,predictions_scale)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
