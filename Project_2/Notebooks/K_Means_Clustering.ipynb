{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Without nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_0null = pd.read_csv(\"training_0null.csv\")\n",
    "teste_0null = pd.read_csv(\"test_0null.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([treino_0null, teste_0null], ignore_index=True)\n",
    "merged_X = merged.drop(columns=['salary']) \n",
    "merged_Y = merged['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create K Means Clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.614325\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_Y,kmeans.predict(merged_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74     34014\n",
      "           1       0.24      0.25      0.24     11208\n",
      "\n",
      "    accuracy                           0.61     45222\n",
      "   macro avg       0.49      0.49      0.49     45222\n",
      "weighted avg       0.62      0.61      0.62     45222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_Y,kmeans.predict(merged_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          24994   9020  34014\n",
      "1           8421   2787  11208\n",
      "All        33415  11807  45222\n"
     ]
    }
   ],
   "source": [
    "confusionNotNull = pd.crosstab(merged_Y, kmeans.predict(merged_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionNotNull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "merged_X,merged_Y = oversample.fit_resample(merged_X,merged_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "merged_X,merged_Y = undersample.fit_resample(merged_X,merged_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.466495\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_Y,kmeans.predict(merged_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.27      0.37     19435\n",
      "           1       0.42      0.75      0.54     13605\n",
      "\n",
      "    accuracy                           0.47     33040\n",
      "   macro avg       0.51      0.51      0.45     33040\n",
      "weighted avg       0.53      0.47      0.44     33040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_Y,kmeans.predict(merged_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0      1    All\n",
      "Actual                       \n",
      "0          5219  14216  19435\n",
      "1          3411  10194  13605\n",
      "All        8630  24410  33040\n"
     ]
    }
   ],
   "source": [
    "confusionNotNull = pd.crosstab(merged_Y, kmeans.predict(merged_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionNotNull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Mode as null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_mode = pd.read_csv(\"training_mode.csv\")\n",
    "teste_mode = pd.read_csv(\"test_mode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([treino_mode, teste_mode], ignore_index=True)\n",
    "merged_X = merged.drop(columns=['salary']) \n",
    "merged_Y = merged['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create K Means Clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.617501\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_Y,kmeans.predict(merged_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74     36080\n",
      "           1       0.23      0.25      0.24     11541\n",
      "\n",
      "    accuracy                           0.62     47621\n",
      "   macro avg       0.49      0.49      0.49     47621\n",
      "weighted avg       0.63      0.62      0.62     47621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_Y,kmeans.predict(merged_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          26537   9543  36080\n",
      "1           8672   2869  11541\n",
      "All        35209  12412  47621\n"
     ]
    }
   ],
   "source": [
    "confusionMode = pd.crosstab(merged_Y, kmeans.predict(merged_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "merged_X,merged_Y = oversample.fit_resample(merged_X,merged_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "merged_X,merged_Y = undersample.fit_resample(merged_X,merged_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.534309\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_Y,kmeans.predict(merged_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.74      0.65     20617\n",
      "           1       0.39      0.24      0.30     14432\n",
      "\n",
      "    accuracy                           0.53     35049\n",
      "   macro avg       0.49      0.49      0.48     35049\n",
      "weighted avg       0.50      0.53      0.51     35049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_Y,kmeans.predict(merged_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          15200  5417  20617\n",
      "1          10905  3527  14432\n",
      "All        26105  8944  35049\n"
     ]
    }
   ],
   "source": [
    "confusionMode = pd.crosstab(merged_Y, kmeans.predict(merged_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - KNN as null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_knn = pd.read_csv(\"training_knn.csv\")\n",
    "teste_knn = pd.read_csv(\"test_knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_knn = pd.concat([treino_knn, teste_knn], ignore_index=True)\n",
    "merged_knn_X = merged_knn.drop(columns=['salary']) \n",
    "merged_knn_Y = merged_knn['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create K Means Clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_knn_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.617375\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_knn_Y,kmeans.predict(merged_knn_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.74      0.74     36080\n",
      "         1.0       0.23      0.25      0.24     11541\n",
      "\n",
      "    accuracy                           0.62     47621\n",
      "   macro avg       0.49      0.49      0.49     47621\n",
      "weighted avg       0.63      0.62      0.62     47621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_knn_Y,kmeans.predict(merged_knn_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0.0        26530   9550  36080\n",
      "1.0         8671   2870  11541\n",
      "All        35201  12420  47621\n"
     ]
    }
   ],
   "source": [
    "confusionKNN = pd.crosstab(merged_knn_Y, kmeans.predict(merged_knn_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "merged_knn_X,merged_knn_Y = oversample.fit_resample(merged_knn_X,merged_knn_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "merged_knn_X,merged_knn_Y = undersample.fit_resample(merged_knn_X,merged_knn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_knn_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.536278\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_knn_Y,kmeans.predict(merged_knn_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.74      0.65     20617\n",
      "         1.0       0.40      0.25      0.30     14432\n",
      "\n",
      "    accuracy                           0.54     35049\n",
      "   macro avg       0.49      0.49      0.48     35049\n",
      "weighted avg       0.51      0.54      0.51     35049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_knn_Y,kmeans.predict(merged_knn_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0.0        15257  5360  20617\n",
      "1.0        10893  3539  14432\n",
      "All        26150  8899  35049\n"
     ]
    }
   ],
   "source": [
    "confusionKNN = pd.crosstab(merged_knn_Y, kmeans.predict(merged_knn_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - No null but using scale instead of ints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv created in Data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_strings = pd.read_csv(\"training_0null_strings.csv\")\n",
    "teste_strings = pd.read_csv(\"test_0null_strings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_scale = pd.concat([treino_strings, teste_strings], ignore_index=True)\n",
    "merged_scale_X = merged_scale.drop(columns=['salary']) \n",
    "merged_scale_Y = merged_scale['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = ['workclass', 'maritalstatus', 'occupation', 'relationship', 'race', 'sex', 'nativecountry']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        merged_scale_X[feature] = le.fit_transform(merged_scale_X[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "merged_scale_X = pd.DataFrame(scaler.fit_transform(merged_scale_X), columns = merged_scale_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create K Means Clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_scale_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict values and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.593848\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_scale_Y,kmeans.predict(merged_scale_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.51      0.65     34014\n",
      "           1       0.36      0.86      0.51     11208\n",
      "\n",
      "    accuracy                           0.59     45222\n",
      "   macro avg       0.64      0.68      0.58     45222\n",
      "weighted avg       0.78      0.59      0.62     45222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_scale_Y,kmeans.predict(merged_scale_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          17213  16801  34014\n",
      "1           1566   9642  11208\n",
      "All        18779  26443  45222\n"
     ]
    }
   ],
   "source": [
    "confusionScale = pd.crosstab(merged_scale_Y, kmeans.predict(merged_scale_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling e Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "merged_scale_X,merged_scale_Y = oversample.fit_resample(merged_scale_X,merged_scale_Y)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7)\n",
    "merged_scale_X,merged_scale_Y = undersample.fit_resample(merged_scale_X,merged_scale_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(merged_scale_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.658081\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(merged_scale_Y,kmeans.predict(merged_scale_X))\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.52      0.64     19435\n",
      "           1       0.55      0.86      0.67     13605\n",
      "\n",
      "    accuracy                           0.66     33040\n",
      "   macro avg       0.70      0.69      0.66     33040\n",
      "weighted avg       0.72      0.66      0.65     33040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_scale_Y,kmeans.predict(merged_scale_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          10043   9392  19435\n",
      "1           1905  11700  13605\n",
      "All        11948  21092  33040\n"
     ]
    }
   ],
   "source": [
    "confusionScale = pd.crosstab(merged_scale_Y, kmeans.predict(merged_scale_X), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusionScale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
